{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeGou/TEDE_Project_1_2023-24/blob/main/tede_project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bchCwFXfSZ2a",
        "outputId": "cac74c3b-3c28-4df0-c067-1321d427dd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ανάλυση Δεδομένων (Data exploration)"
      ],
      "metadata": {
        "id": "CQplFshM_6ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of train_2019.csv"
      ],
      "metadata": {
        "id": "moY9TA3zOuGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read listings.csv files for April, February, and March\n",
        "april_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/april/listings.csv\")\n",
        "february_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/febrouary/listings.csv\")\n",
        "march_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/march/listings.csv\")\n",
        "\n",
        "# Add a new column named \"month\" to each DataFrame\n",
        "april_listings['month'] = 'April'\n",
        "february_listings['month'] = 'February'\n",
        "march_listings['month'] = 'March'\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "all_listings = pd.concat([april_listings, february_listings, march_listings])\n",
        "\n",
        "# Select the required columns\n",
        "train_df = all_listings[['id', 'zipcode', 'transit', 'bedrooms', 'beds', 'review_scores_rating', 'number_of_reviews',\n",
        "                        'neighbourhood', 'name', 'latitude', 'longitude', 'last_review', 'instant_bookable',\n",
        "                        'host_since', 'host_response_rate', 'host_identity_verified', 'host_has_profile_pic',\n",
        "                        'first_review', 'description', 'city', 'cancellation_policy', 'bed_type', 'bathrooms',\n",
        "                        'accommodates', 'amenities', 'room_type', 'property_type', 'price', 'availability_365',\n",
        "                        'minimum_nights', 'month']]\n",
        "\n",
        "# We decided to drop the rows that are exactly the same for each month. As a result, there is some more data for February,\n",
        "# because it is the first month in our train.csv (keep=first was used in all drop_duplicate calls)\n",
        "train_df = train_df.drop_duplicates( subset = ['id', 'zipcode', 'transit', 'bedrooms', 'beds', 'review_scores_rating', 'number_of_reviews',\n",
        "                        'neighbourhood', 'name', 'latitude', 'longitude', 'last_review', 'instant_bookable',\n",
        "                        'host_since', 'host_response_rate', 'host_identity_verified', 'host_has_profile_pic',\n",
        "                        'first_review', 'description', 'city', 'cancellation_policy', 'bed_type', 'bathrooms',\n",
        "                        'accommodates', 'amenities', 'room_type', 'property_type', 'price', 'availability_365',\n",
        "                        'minimum_nights', 'month'] )\n",
        "\n",
        "# Also, we drop all rows with empty or Nan values.\n",
        "train_df = train_df.dropna()\n",
        "\n",
        "\n",
        "# Cleaning up some data\n",
        "\n",
        "# Zipcode column is transformed to numeric format and some string values are deleted\n",
        "train_df['zipcode'] = train_df['zipcode'].str.replace(r'\\D', '', regex=True).astype('float').astype('Int64')\n",
        "\n",
        "# Similar work for 'bedrooms', 'beds', and 'bathrooms' columns\n",
        "train_df['bedrooms'] = pd.to_numeric(train_df['bedrooms'], errors='coerce', downcast='integer')\n",
        "train_df['beds'] = pd.to_numeric(train_df['beds'], errors='coerce', downcast='integer')\n",
        "train_df['bathrooms'] = pd.to_numeric(train_df['bathrooms'], errors='coerce', downcast='integer')\n",
        "\n",
        "# Removing $ and some other symbols from the price column\n",
        "train_df['price'] = train_df['price'].str.replace(r'[^0-9]', '', regex=True).astype(int)\n",
        "\n",
        "# For the 'zipcode' column, regex pattern r'\\D' is used to remove non-digit characters. The column is then converted to a float to handle potential missing values (NaN) and then to an integer.\n",
        "# For 'bedrooms', 'beds', and 'bathrooms' columns, pd.to_numeric() is used with the downcast parameter set to 'integer' for efficient memory usage and error handling.\n",
        "# For the 'price' column, regex pattern r'[^0-9]' is used to remove all non-numeric characters. Then, the column is converted to an integer.\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfU_tSb2c8qi",
        "outputId": "ead09da0-d224-45e3-ad72-99c6d3fe551d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-95a7be8ff8a9>:4: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  april_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/april/listings.csv\")\n",
            "<ipython-input-1-95a7be8ff8a9>:5: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  february_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/febrouary/listings.csv\")\n",
            "<ipython-input-1-95a7be8ff8a9>:6: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  march_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/march/listings.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creation of train_2023.csv"
      ],
      "metadata": {
        "id": "pEx15VBdO7bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read listings.csv files for April, February, and March\n",
        "april_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/april/listings.csv\")\n",
        "february_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/febrouary/listings.csv\")\n",
        "march_listings = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/march/listings.csv\")\n",
        "\n",
        "# Add a new column named \"month\" to each DataFrame\n",
        "april_listings['month'] = 'April'\n",
        "february_listings['month'] = 'February'\n",
        "march_listings['month'] = 'March'\n",
        "\n",
        "# Concatenate the DataFrames\n",
        "all_listings = pd.concat([april_listings, february_listings, march_listings])\n",
        "\n",
        "# Select the required columns\n",
        "train_df = all_listings[['id', 'zipcode', 'transit', 'bedrooms', 'beds', 'review_scores_rating', 'number_of_reviews',\n",
        "                        'neighbourhood', 'name', 'latitude', 'longitude', 'last_review', 'instant_bookable',\n",
        "                        'host_since', 'host_response_rate', 'host_identity_verified', 'host_has_profile_pic',\n",
        "                        'first_review', 'description', 'city', 'cancellation_policy', 'bed_type', 'bathrooms',\n",
        "                        'accommodates', 'amenities', 'room_type', 'property_type', 'price', 'availability_365',\n",
        "                        'minimum_nights', 'month']]\n",
        "\n",
        "# We decided to drop the rows that are exactly the same for each month. As a result, there is some more data for February,\n",
        "# because it is the first month in our train.csv (keep=first was used in all drop_duplicate calls)\n",
        "train_df = train_df.drop_duplicates( subset = ['id', 'zipcode', 'transit', 'bedrooms', 'beds', 'review_scores_rating', 'number_of_reviews',\n",
        "                        'neighbourhood', 'name', 'latitude', 'longitude', 'last_review', 'instant_bookable',\n",
        "                        'host_since', 'host_response_rate', 'host_identity_verified', 'host_has_profile_pic',\n",
        "                        'first_review', 'description', 'city', 'cancellation_policy', 'bed_type', 'bathrooms',\n",
        "                        'accommodates', 'amenities', 'room_type', 'property_type', 'price', 'availability_365',\n",
        "                        'minimum_nights', 'month'] )\n",
        "\n",
        "# Also, we drop all rows with empty or Nan values.\n",
        "train_df = train_df.dropna()\n",
        "\n",
        "\n",
        "# Cleaning up some data\n",
        "\n",
        "# Zipcode column is transformed to numeric format and some string values are deleted\n",
        "train_df['zipcode'] = train_df['zipcode'].str.replace(r'\\D', '', regex=True).astype('float').astype('Int64')\n",
        "\n",
        "# Similar work for 'bedrooms', 'beds', and 'bathrooms' columns\n",
        "train_df['bedrooms'] = pd.to_numeric(train_df['bedrooms'], errors='coerce', downcast='integer')\n",
        "train_df['beds'] = pd.to_numeric(train_df['beds'], errors='coerce', downcast='integer')\n",
        "train_df['bathrooms'] = pd.to_numeric(train_df['bathrooms'], errors='coerce', downcast='integer')\n",
        "\n",
        "# Removing $ and some other symbols from the price column\n",
        "train_df['price'] = train_df['price'].str.replace(r'[^0-9]', '', regex=True).astype(int)\n",
        "\n",
        "# For the 'zipcode' column, regex pattern r'\\D' is used to remove non-digit characters. The column is then converted to a float to handle potential missing values (NaN) and then to an integer.\n",
        "# For 'bedrooms', 'beds', and 'bathrooms' columns, pd.to_numeric() is used with the downcast parameter set to 'integer' for efficient memory usage and error handling.\n",
        "# For the 'price' column, regex pattern r'[^0-9]' is used to remove all non-numeric characters. Then, the column is converted to an integer.\n",
        "\n",
        "# Save to CSV\n",
        "train_df.to_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv\", index=False)"
      ],
      "metadata": {
        "id": "V9b-Gw8zO_ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the most common room_type for your data?"
      ],
      "metadata": {
        "id": "XZ_J17X2_DmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Year 2019"
      ],
      "metadata": {
        "id": "iTDHt7pXOJ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "train_2019_df = pd.read_csv(\"/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv\")\n",
        "\n",
        "# 1.1 Ποιός είναι ο πιο συχνός τύπος room_type για τα δεδομένα σας;\n",
        "room_type_counts = train_2019_df['room_type'].value_counts()\n",
        "most_common_room_type = room_type_counts.idxmax()\n",
        "print(\"Ο πιο συχνός τύπος room_type είναι:\", most_common_room_type)\n",
        "\n",
        "# 1.2 Φτιάξτε γράφημα ή γραφήματα που δείχνουν την πορεία των τιμών για το διάστημα των 3 μηνών.\n",
        "# Assuming there's a column 'price' in listings_df\n",
        "train_2019_df['price'] = train_2019_df['price'].str.replace('$', '').astype(float)\n",
        "train_2019_df['host_since'] = pd.to_datetime(train_2019_df['host_since'])\n",
        "\n",
        "train_2019_df.set_index('host_since').resample('M')['price'].mean().plot()\n",
        "plt.title('Μέση τιμή καταχωρήσεων ανά μήνα')\n",
        "plt.xlabel('Μήνας')\n",
        "plt.ylabel('Μέση τιμή')\n",
        "plt.show()\n",
        "\n",
        "# 1.3 Ποιές είναι οι 5 πρώτες γειτονιές με τις περισσότερες κριτικές;\n",
        "top_neighbourhood_reviews = train_2019_df.groupby('neighbourhood')['number_of_reviews'].sum().nlargest(5)\n",
        "print(\"Οι 5 πρώτες γειτονιές με τις περισσότερες κριτικές είναι:\")\n",
        "print(top_neighbourhood_reviews)\n",
        "\n",
        "# 1.4 Ποιά είναι η γειτονιά με τις περισσότερες καταχωρήσεις ακινήτων;\n",
        "neighbourhood_with_most_listings = train_2019_df['neighbourhood'].value_counts().idxmax()\n",
        "print(\"Η γειτονιά με τις περισσότερες καταχωρήσεις ακινήτων είναι:\", neighbourhood_with_most_listings)\n",
        "\n",
        "# 1.5 Πόσες είναι οι καταχωρήσεις ανά γειτονιά και ανά μήνα;\n",
        "listings_per_neighbourhood = train_2019_df['neighbourhood'].value_counts()\n",
        "listings_per_month = train_2019_df.set_index('host_since').resample('M')['id'].count()\n",
        "\n",
        "# 1.6 Σχεδιάστε το ιστόγραμμα της μεταβλητής neighborhood.\n",
        "train_2019_df['neighbourhood'].value_counts().plot(kind='bar')\n",
        "plt.title('Ιστόγραμμα της μεταβλητής neighbourhood')\n",
        "plt.xlabel('Γειτονιά')\n",
        "plt.ylabel('Πλήθος καταχωρήσεων')\n",
        "plt.show()\n",
        "\n",
        "# 1.7 Ποιος είναι ο πιο συχνός τύπος δωματίου (room_type) σε κάθε γειτονιά (neighborhood);\n",
        "room_type_by_neighbourhood = train_2019_df.groupby('neighbourhood')['room_type'].agg(pd.Series.mode)\n",
        "print(\"Ο πιο συχνός τύπος δωματίου σε κάθε γειτονιά είναι:\")\n",
        "print(room_type_by_neighbourhood)\n"
      ],
      "metadata": {
        "id": "vbeOgr8edcMV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d29ddffc-a80f-4781-ab8b-a5e89c069ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-27c0c432bf01>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_2019_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1.1 Ποιός είναι ο πιο συχνός τύπος room_type για τα δεδομένα σας;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/tede_project_1/data/2019/train_2019.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Year 2023"
      ],
      "metadata": {
        "id": "EvBykOklOoav"
      }
    }
  ]
}